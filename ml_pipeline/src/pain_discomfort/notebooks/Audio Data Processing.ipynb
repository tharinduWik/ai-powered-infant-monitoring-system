{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aaeb6f7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Data Processing with AUGMENTATION...\n",
      "Processing 'belly pain' (Class 1). Found 127 files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\anaconda3\\Lib\\site-packages\\paramiko\\transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated and will be removed in a future release\n",
      "  \"class\": algorithms.Blowfish,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 'cold_hot' (Class 1). Found 107 files.\n",
      "Processing 'discomfort' (Class 1). Found 138 files.\n",
      "Processing 'hungry' (Class 0). Found 382 files.\n",
      "Processing 'tired' (Class 0). Found 136 files.\n",
      "Processing 'burping' (Class 0). Found 118 files.\n",
      "Processing 'lonely' (Class 0). Found 11 files.\n",
      "Processing 'scared' (Class 0). Found 20 files.\n",
      "\n",
      "PROCESSING COMPLETE!\n",
      "Total samples processed: 2155\n",
      "Class Distribution:\n",
      "label\n",
      "1    1488\n",
      "0     667\n",
      "Name: count, dtype: int64\n",
      "Saved to processed.csv'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "# PASTE YOUR FOLDER PATH HERE\n",
    "DATASET_PATH = r\"../data/raw/Audio/Baby Cry Dataset/\" \n",
    "\n",
    "# MAPPING: 1 = Pain, 0 = No Pain\n",
    "LABEL_MAP = {\n",
    "    'belly pain': 1, 'cold_hot': 1, 'discomfort': 1,  # PAIN CLASSES\n",
    "    'hungry': 0, 'tired': 0, 'burping': 0, 'lonely': 0, 'scared': 0 # NO PAIN CLASSES\n",
    "}\n",
    "\n",
    "def add_noise(data):\n",
    "    \"\"\"Adds random static noise\"\"\"\n",
    "    noise_amp = 0.005 * np.random.uniform() * np.amax(data)\n",
    "    return data + noise_amp * np.random.normal(size=data.shape)\n",
    "\n",
    "def shift_pitch(data, sr):\n",
    "    \"\"\"Changes the pitch slightly (higher/lower)\"\"\"\n",
    "    return librosa.effects.pitch_shift(y=data, sr=sr, n_steps=2.0)\n",
    "\n",
    "def stretch_time(data):\n",
    "    \"\"\"Speeds up the audio slightly\"\"\"\n",
    "    return librosa.effects.time_stretch(y=data, rate=1.2)\n",
    "\n",
    "def extract_features(y, sr):\n",
    "    \"\"\"Extracts MFCCs (the main feature for audio AI)\"\"\"\n",
    "    # MFCCs\n",
    "    mfccs = np.mean(librosa.feature.mfcc(y=y, sr=sr, n_mfcc=40).T, axis=0)\n",
    "    # Mel Spectrogram\n",
    "    mel = np.mean(librosa.feature.melspectrogram(y=y, sr=sr).T, axis=0)\n",
    "    \n",
    "    return np.hstack([mfccs, mel])\n",
    "\n",
    "# --- MAIN LOOP ---\n",
    "features = []\n",
    "labels = []\n",
    "\n",
    "print(\"Starting Data Processing with AUGMENTATION...\")\n",
    "\n",
    "for folder_name, label in LABEL_MAP.items():\n",
    "    folder_path = os.path.join(DATASET_PATH, folder_name)\n",
    "    audio_files = glob.glob(os.path.join(folder_path, \"*.wav\"))\n",
    "    \n",
    "    print(f\"Processing '{folder_name}' (Class {label}). Found {len(audio_files)} files.\")\n",
    "    \n",
    "    for file in audio_files:\n",
    "        try:\n",
    "            # Load Audio (limit to 5 seconds for consistency)\n",
    "            y, sr = librosa.load(file, duration=5.0)\n",
    "            \n",
    "            # 1. Save the ORIGINAL file\n",
    "            feat = extract_features(y, sr)\n",
    "            features.append(feat)\n",
    "            labels.append(label)\n",
    "            \n",
    "            # 2. IF CLASS IS PAIN (1) -> AUGMENT DATA\n",
    "            # We create artificial copies to balance the dataset\n",
    "            if label == 1:\n",
    "                # Augment 1: Add Noise\n",
    "                y_noise = add_noise(y)\n",
    "                features.append(extract_features(y_noise, sr))\n",
    "                labels.append(label)\n",
    "                \n",
    "                # Augment 2: Pitch Shift (Sound slightly higher)\n",
    "                y_pitch = shift_pitch(y, sr)\n",
    "                features.append(extract_features(y_pitch, sr))\n",
    "                labels.append(label)\n",
    "                \n",
    "                # Augment 3: Time Stretch (Faster)\n",
    "                y_stretch = stretch_time(y)\n",
    "                features.append(extract_features(y_stretch, sr))\n",
    "                labels.append(label)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error file {file}: {e}\")\n",
    "\n",
    "# --- SAVE ---\n",
    "cols = [f'mfcc_{i}' for i in range(40)] + [f'mel_{i}' for i in range(128)]\n",
    "df = pd.DataFrame(features, columns=cols)\n",
    "df['label'] = labels\n",
    "\n",
    "print(f\"\\nPROCESSING COMPLETE!\")\n",
    "print(f\"Total samples processed: {len(df)}\")\n",
    "print(f\"Class Distribution:\\n{df['label'].value_counts()}\")\n",
    "\n",
    "df.to_csv(\"../data/processed/processed.csv\", index=False)\n",
    "print(\"Saved to processed.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
