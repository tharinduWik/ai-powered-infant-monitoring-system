{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "341d9ed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verifying packages...\n",
      "  ‚úì numpy\n",
      "  ‚úó opencv-python - installing...\n",
      "    ‚úì opencv-python installed\n",
      "    ‚úì opencv-python installed\n",
      "  ‚úó mediapipe - installing...\n",
      "  ‚úó mediapipe - installing...\n",
      "    ‚úì mediapipe installed\n",
      "  ‚úì pandas\n",
      "  ‚úó scikit-learn - installing...\n",
      "    ‚úì mediapipe installed\n",
      "  ‚úì pandas\n",
      "  ‚úó scikit-learn - installing...\n",
      "    ‚úì scikit-learn installed\n",
      "  ‚úì matplotlib\n",
      "  ‚úì seaborn\n",
      "  ‚úì joblib\n",
      "\n",
      "‚úì All packages ready!\n",
      "    ‚úì scikit-learn installed\n",
      "  ‚úì matplotlib\n",
      "  ‚úì seaborn\n",
      "  ‚úì joblib\n",
      "\n",
      "‚úì All packages ready!\n"
     ]
    }
   ],
   "source": [
    "# Verify all required packages are installed and import them\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "packages_needed = [\n",
    "    'numpy<2',\n",
    "    'opencv-python',\n",
    "    'mediapipe',\n",
    "    'pandas',\n",
    "    'scikit-learn',\n",
    "    'matplotlib',\n",
    "    'seaborn',\n",
    "    'joblib'\n",
    "]\n",
    "\n",
    "print(\"Verifying packages...\")\n",
    "for pkg in packages_needed:\n",
    "    pkg_name = pkg.split('<')[0].split('>')[0].split('==')[0]\n",
    "    try:\n",
    "        __import__(pkg_name.replace('-', '_'))\n",
    "        print(f\"  ‚úì {pkg_name}\")\n",
    "    except ImportError:\n",
    "        print(f\"  ‚úó {pkg_name} - installing...\")\n",
    "        subprocess.check_call([sys.executable, '-m', 'pip', 'install', pkg, '-q'])\n",
    "        print(f\"    ‚úì {pkg_name} installed\")\n",
    "\n",
    "print(\"\\n‚úì All packages ready!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a0838a5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy version: 2.2.6\n",
      "OpenCV version: 4.11.0\n",
      "‚ÑπÔ∏è MediaPipe not available in this kernel session (may work after restart)\n",
      "‚úì OpenCV Haar Cascade loaded (will use as fallback)\n",
      "\n",
      "‚úì All imports and initialization complete!\n",
      "\n",
      "Detection methods available:\n",
      "  - MediaPipe: ‚úó No (fallback to Haar)\n",
      "  - Haar Cascade: ‚úì YES (always available)\n",
      "‚ÑπÔ∏è MediaPipe not available in this kernel session (may work after restart)\n",
      "‚úì OpenCV Haar Cascade loaded (will use as fallback)\n",
      "\n",
      "‚úì All imports and initialization complete!\n",
      "\n",
      "Detection methods available:\n",
      "  - MediaPipe: ‚úó No (fallback to Haar)\n",
      "  - Haar Cascade: ‚úì YES (always available)\n"
     ]
    }
   ],
   "source": [
    "# Import all required libraries\n",
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import urllib.request\n",
    "import warnings\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"OpenCV version: {cv2.__version__}\")\n",
    "\n",
    "# Initialize MediaPipe Face Detection (most robust option)\n",
    "use_mediapipe = False\n",
    "try:\n",
    "    import mediapipe as mp\n",
    "    mp_face_detection = mp.solutions.face_detection\n",
    "    face_detection = mp_face_detection.FaceDetection(model_selection=1, min_detection_confidence=0.3)\n",
    "    use_mediapipe = True\n",
    "    print(f\"‚úì MediaPipe Face Detection initialized!\")\n",
    "except (ImportError, ModuleNotFoundError):\n",
    "    print(\"‚ÑπÔ∏è MediaPipe not available in this kernel session (may work after restart)\")\n",
    "    face_detection = None\n",
    "\n",
    "# Initialize OpenCV's face detector (Haar Cascade - built-in, fallback option)\n",
    "face_cascade_path = cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'\n",
    "face_cascade = cv2.CascadeClassifier(face_cascade_path)\n",
    "print(f\"‚úì OpenCV Haar Cascade loaded (will use as fallback)\")\n",
    "\n",
    "# Note: DNN model download URL no longer works, using fallbacks\n",
    "net = None\n",
    "use_dnn = False\n",
    "\n",
    "print(\"\\n‚úì All imports and initialization complete!\")\n",
    "print(f\"\\nDetection methods available:\")\n",
    "print(f\"  - MediaPipe: {'‚úì YES' if use_mediapipe else '‚úó No (fallback to Haar)'}\")\n",
    "print(f\"  - Haar Cascade: ‚úì YES (always available)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9b8dea2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Face detection and feature extraction functions defined!\n",
      "============================================================\n",
      "Detection hierarchy:\n",
      "  1Ô∏è‚É£  MediaPipe (most robust for expressions)\n",
      "  2Ô∏è‚É£  OpenCV DNN (accurate)\n",
      "  3Ô∏è‚É£  Haar Cascade (fast fallback)\n",
      "  4Ô∏è‚É£  Center crop (when no face detected)\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "def detect_faces_mediapipe(image):\n",
    "    \"\"\"\n",
    "    Robust face detection using MediaPipe.\n",
    "    Handles side views and crying expressions much better than Haar/DNN.\n",
    "    \"\"\"\n",
    "    h, w = image.shape[:2]\n",
    "    # Convert BGR to RGB for MediaPipe\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    results = face_detection.process(image_rgb)\n",
    "    \n",
    "    faces = []\n",
    "    if results.detections:\n",
    "        for detection in results.detections:\n",
    "            bboxC = detection.location_data.relative_bounding_box\n",
    "            x = int(bboxC.xmin * w)\n",
    "            y = int(bboxC.ymin * h)\n",
    "            w_box = int(bboxC.width * w)\n",
    "            h_box = int(bboxC.height * h)\n",
    "            \n",
    "            # Ensure coordinates are within image boundaries\n",
    "            x = max(0, x)\n",
    "            y = max(0, y)\n",
    "            w_box = min(w_box, w - x)\n",
    "            h_box = min(h_box, h - y)\n",
    "            \n",
    "            if w_box > 0 and h_box > 0:\n",
    "                faces.append((x, y, w_box, h_box))\n",
    "    \n",
    "    return faces\n",
    "\n",
    "def detect_faces_dnn(image):\n",
    "    \"\"\"Detect faces using OpenCV DNN (accurate fallback).\"\"\"\n",
    "    h, w = image.shape[:2]\n",
    "    blob = cv2.dnn.blobFromImage(image, 1.0, (300, 300), [104, 117, 123], False, False)\n",
    "    net.setInput(blob)\n",
    "    detections = net.forward()\n",
    "    \n",
    "    faces = []\n",
    "    for i in range(detections.shape[2]):\n",
    "        confidence = detections[0, 0, i, 2]\n",
    "        if confidence > 0.3:\n",
    "            box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "            (x, y, x2, y2) = box.astype(\"int\")\n",
    "            x, y = max(0, x), max(0, y)\n",
    "            x2, y2 = min(w, x2), min(h, y2)\n",
    "            if x2 > x and y2 > y:\n",
    "                faces.append((x, y, x2-x, y2-y))\n",
    "    \n",
    "    return faces\n",
    "\n",
    "def detect_faces_haar(image):\n",
    "    \"\"\"Detect faces using Haar Cascade (fastest fallback).\"\"\"\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=3)\n",
    "    return [(int(x), int(y), int(w), int(h)) for x, y, w, h in faces]\n",
    "\n",
    "def auto_rotate_image(image):\n",
    "    \"\"\"\n",
    "    Automatically detect and correct image orientation.\n",
    "    Handles images in landscape, portrait, and rotated positions.\n",
    "    \"\"\"\n",
    "    h, w = image.shape[:2]\n",
    "    rotations = [0, 90, 180, 270]\n",
    "    best_faces = None\n",
    "    best_rotation = 0\n",
    "    max_face_area = 0\n",
    "    \n",
    "    for angle in rotations:\n",
    "        if angle == 0:\n",
    "            rotated = image.copy()\n",
    "        else:\n",
    "            center = (w // 2, h // 2)\n",
    "            rotation_matrix = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "            rotated = cv2.warpAffine(image, rotation_matrix, (w, h))\n",
    "        \n",
    "        # Try MediaPipe first (most robust)\n",
    "        if use_mediapipe:\n",
    "            faces = detect_faces_mediapipe(rotated)\n",
    "        elif use_dnn:\n",
    "            faces = detect_faces_dnn(rotated)\n",
    "        else:\n",
    "            faces = detect_faces_haar(rotated)\n",
    "        \n",
    "        # Calculate total face area\n",
    "        total_area = sum(f[2] * f[3] for f in faces)\n",
    "        \n",
    "        if total_area > max_face_area:\n",
    "            max_face_area = total_area\n",
    "            best_faces = faces\n",
    "            best_rotation = angle\n",
    "    \n",
    "    # Return the orientation with best face detection\n",
    "    if best_rotation == 0:\n",
    "        return image, best_rotation\n",
    "    else:\n",
    "        center = (w // 2, h // 2)\n",
    "        rotation_matrix = cv2.getRotationMatrix2D(center, best_rotation, 1.0)\n",
    "        rotated = cv2.warpAffine(image, rotation_matrix, (w, h))\n",
    "        return rotated, best_rotation\n",
    "\n",
    "def extract_face_features(image, image_path=\"\"):\n",
    "    \"\"\"\n",
    "    Extract features from detected face region.\n",
    "    Automatically handles image orientation.\n",
    "    Falls back to center crop if no face detected.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        original_h, original_w = image.shape[:2]\n",
    "        \n",
    "        # AUTO-ROTATE to find best orientation for face detection\n",
    "        image, rotation_used = auto_rotate_image(image)\n",
    "        \n",
    "        # Detect faces (try MediaPipe first, then fallbacks)\n",
    "        if use_mediapipe:\n",
    "            faces = detect_faces_mediapipe(image)\n",
    "        elif use_dnn:\n",
    "            faces = detect_faces_dnn(image)\n",
    "        else:\n",
    "            faces = detect_faces_haar(image)\n",
    "        \n",
    "        face_region = None\n",
    "        fallback_used = False\n",
    "        \n",
    "        if len(faces) > 0:\n",
    "            # Face found: Crop to largest face\n",
    "            x, y, w, h = max(faces, key=lambda f: f[2]*f[3])\n",
    "            \n",
    "            # Validate region\n",
    "            if x + w > image.shape[1] or y + h > image.shape[0]:\n",
    "                raise ValueError(\"Face region out of bounds\")\n",
    "            \n",
    "            face_region = image[y:y+h, x:x+w]\n",
    "            \n",
    "            if face_region.size == 0 or face_region.shape[0] < 10 or face_region.shape[1] < 10:\n",
    "                raise ValueError(\"Face region too small\")\n",
    "        else:\n",
    "            # NO FACE FOUND: Use center crop as fallback\n",
    "            h, w = image.shape[:2]\n",
    "            center_x, center_y = w // 2, h // 2\n",
    "            # Crop the center 60% of the image\n",
    "            crop_h, crop_w = int(h * 0.6), int(w * 0.6)\n",
    "            start_x = max(0, center_x - crop_w // 2)\n",
    "            start_y = max(0, center_y - crop_h // 2)\n",
    "            face_region = image[start_y:start_y+crop_h, start_x:start_x+crop_w]\n",
    "            fallback_used = True\n",
    "        \n",
    "        # Extract features from face region\n",
    "        gray = cv2.cvtColor(face_region, cv2.COLOR_BGR2GRAY)\n",
    "        gray = cv2.normalize(gray, None, 0, 255, cv2.NORM_MINMAX)\n",
    "        \n",
    "        # 1. Edge density (Sobel)\n",
    "        sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)\n",
    "        sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)\n",
    "        edges = np.sqrt(sobelx**2 + sobely**2)\n",
    "        edge_density = np.mean(edges) / 255.0\n",
    "        \n",
    "        # 2. Contrast (standard deviation of intensity)\n",
    "        contrast = np.std(gray) / 255.0\n",
    "        \n",
    "        # 3. Brightness (mean intensity)\n",
    "        brightness = np.mean(gray) / 255.0\n",
    "        \n",
    "        # 4. Texture variance (local pattern variation)\n",
    "        laplacian = cv2.Laplacian(gray, cv2.CV_64F)\n",
    "        texture_var = np.var(laplacian) / (255.0**2)\n",
    "        \n",
    "        # 5. Histogram entropy (information content)\n",
    "        hist = cv2.calcHist([gray], [0], None, [256], [0, 256])\n",
    "        hist = hist.flatten() / hist.sum()\n",
    "        entropy = -np.sum(hist[hist > 0] * np.log2(hist[hist > 0]))\n",
    "        entropy = entropy / 8.0\n",
    "        \n",
    "        features = {\n",
    "            \"Edge_Density\": float(edge_density),\n",
    "            \"Contrast\": float(contrast),\n",
    "            \"Brightness\": float(brightness),\n",
    "            \"Texture_Variance\": float(texture_var),\n",
    "            \"Entropy\": float(entropy),\n",
    "            \"Face_Size\": face_region.shape[0] * face_region.shape[1],\n",
    "            \"Image_Rotation\": rotation_used,\n",
    "            \"Fallback_Used\": fallback_used  # Track if center crop was used\n",
    "        }\n",
    "        \n",
    "        return features\n",
    "        \n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "print(\"Face detection and feature extraction functions defined!\")\n",
    "print(\"=\" * 60)\n",
    "print(\"Detection hierarchy:\")\n",
    "print(\"  1Ô∏è‚É£  MediaPipe (most robust for expressions)\")\n",
    "print(\"  2Ô∏è‚É£  OpenCV DNN (accurate)\")\n",
    "print(\"  3Ô∏è‚É£  Haar Cascade (fast fallback)\")\n",
    "print(\"  4Ô∏è‚É£  Center crop (when no face detected)\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6167b5b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting processing... this may take a few minutes.\n",
      "Debug mode: True\n",
      "\n",
      "Processing Folder: 0 (Calm) - 135 images\n",
      "  ‚úì Extracted: 135/135 images\n",
      "    - 53 used fallback center crop\n",
      "Processing Folder: 0.5 (Calm) - 3 images\n",
      "  ‚úì Extracted: 135/135 images\n",
      "    - 53 used fallback center crop\n",
      "Processing Folder: 0.5 (Calm) - 3 images\n",
      "  ‚úì Extracted: 3/3 images\n",
      "    - 3 used fallback center crop\n",
      "Processing Folder: 1 (Calm) - 6 images\n",
      "  ‚úì Extracted: 3/3 images\n",
      "    - 3 used fallback center crop\n",
      "Processing Folder: 1 (Calm) - 6 images\n",
      "  ‚úì Extracted: 6/6 images\n",
      "    - 4 used fallback center crop\n",
      "Processing Folder: 1.5 (Calm) - 21 images\n",
      "  ‚úì Extracted: 6/6 images\n",
      "    - 4 used fallback center crop\n",
      "Processing Folder: 1.5 (Calm) - 21 images\n",
      "  ‚úì Extracted: 21/21 images\n",
      "    - 8 used fallback center crop\n",
      "Processing Folder: 2 (Calm) - 19 images\n",
      "  ‚úì Extracted: 21/21 images\n",
      "    - 8 used fallback center crop\n",
      "Processing Folder: 2 (Calm) - 19 images\n",
      "  ‚úì Extracted: 19/19 images\n",
      "    - 7 used fallback center crop\n",
      "Processing Folder: 2.5 (Discomfort) - 8 images\n",
      "  ‚úì Extracted: 19/19 images\n",
      "    - 7 used fallback center crop\n",
      "Processing Folder: 2.5 (Discomfort) - 8 images\n",
      "  ‚úì Extracted: 8/8 images\n",
      "    - 4 used fallback center crop\n",
      "Processing Folder: 3 (Discomfort) - 37 images\n",
      "  ‚úì Extracted: 8/8 images\n",
      "    - 4 used fallback center crop\n",
      "Processing Folder: 3 (Discomfort) - 37 images\n",
      "  ‚úì Extracted: 37/37 images\n",
      "    - 19 used fallback center crop\n",
      "Processing Folder: 3.5 (Discomfort) - 17 images\n",
      "  ‚úì Extracted: 37/37 images\n",
      "    - 19 used fallback center crop\n",
      "Processing Folder: 3.5 (Discomfort) - 17 images\n",
      "  ‚úì Extracted: 17/17 images\n",
      "    - 6 used fallback center crop\n",
      "Processing Folder: 4 (Discomfort) - 33 images\n",
      "  ‚úì Extracted: 17/17 images\n",
      "    - 6 used fallback center crop\n",
      "Processing Folder: 4 (Discomfort) - 33 images\n",
      "  ‚úì Extracted: 33/33 images\n",
      "    - 15 used fallback center crop\n",
      "Processing Folder: 4.5 (Discomfort) - 8 images\n",
      "  ‚úì Extracted: 33/33 images\n",
      "    - 15 used fallback center crop\n",
      "Processing Folder: 4.5 (Discomfort) - 8 images\n",
      "  ‚úì Extracted: 8/8 images\n",
      "    - 3 used fallback center crop\n",
      "Processing Folder: 5 (Severe Pain) - 46 images\n",
      "  ‚úì Extracted: 8/8 images\n",
      "    - 3 used fallback center crop\n",
      "Processing Folder: 5 (Severe Pain) - 46 images\n",
      "  ‚úì Extracted: 46/46 images\n",
      "    - 24 used fallback center crop\n",
      "Processing Folder: 5.5 (Severe Pain) - 7 images\n",
      "  ‚úì Extracted: 46/46 images\n",
      "    - 24 used fallback center crop\n",
      "Processing Folder: 5.5 (Severe Pain) - 7 images\n",
      "  ‚úì Extracted: 7/7 images\n",
      "    - 2 used fallback center crop\n",
      "Processing Folder: 6 (Severe Pain) - 24 images\n",
      "  ‚úì Extracted: 7/7 images\n",
      "    - 2 used fallback center crop\n",
      "Processing Folder: 6 (Severe Pain) - 24 images\n",
      "  ‚úì Extracted: 24/24 images\n",
      "    - 6 used fallback center crop\n",
      "Processing Folder: 6.5 (Severe Pain) - 15 images\n",
      "  ‚úì Extracted: 24/24 images\n",
      "    - 6 used fallback center crop\n",
      "Processing Folder: 6.5 (Severe Pain) - 15 images\n",
      "  ‚úì Extracted: 15/15 images\n",
      "    - 6 used fallback center crop\n",
      "Processing Folder: 7 (Severe Pain) - 123 images\n",
      "  ‚úì Extracted: 15/15 images\n",
      "    - 6 used fallback center crop\n",
      "Processing Folder: 7 (Severe Pain) - 123 images\n",
      "  ‚úì Extracted: 123/123 images\n",
      "    - 74 used fallback center crop\n",
      "Processing Folder: 8 (Severe Pain) - 1 images\n",
      "  ‚úì Extracted: 123/123 images\n",
      "    - 74 used fallback center crop\n",
      "Processing Folder: 8 (Severe Pain) - 1 images\n",
      "  ‚úì Extracted: 1/1 images\n",
      "\n",
      "======================================================================\n",
      "PROCESSING COMPLETE\n",
      "======================================================================\n",
      "Total files scanned:         503\n",
      "Images successfully loaded:  503\n",
      "Faces detected:              269\n",
      "Fallback crops (no face):    234\n",
      "Total extracted:             503\n",
      "Load errors:                 0\n",
      "Success rate:                100.0%\n",
      "\n",
      "‚úì Processed 503 images ‚Üí Saved to: ../data/processed/processed_pain_img_biomarkers.csv\n",
      "\n",
      "Data shape: (503, 12)\n",
      "\n",
      "Classes distribution:\n",
      "Label_String\n",
      "Calm           184\n",
      "Discomfort     103\n",
      "Severe Pain    216\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Rotation statistics:\n",
      "Image_Rotation\n",
      "0      284\n",
      "90      61\n",
      "180     89\n",
      "270     69\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Fallback usage:\n",
      "  - Fallback used: 234 images (46.5%)\n",
      "  - Face detected: 269 images (53.5%)\n",
      "  ‚úì Extracted: 1/1 images\n",
      "\n",
      "======================================================================\n",
      "PROCESSING COMPLETE\n",
      "======================================================================\n",
      "Total files scanned:         503\n",
      "Images successfully loaded:  503\n",
      "Faces detected:              269\n",
      "Fallback crops (no face):    234\n",
      "Total extracted:             503\n",
      "Load errors:                 0\n",
      "Success rate:                100.0%\n",
      "\n",
      "‚úì Processed 503 images ‚Üí Saved to: ../data/processed/processed_pain_img_biomarkers.csv\n",
      "\n",
      "Data shape: (503, 12)\n",
      "\n",
      "Classes distribution:\n",
      "Label_String\n",
      "Calm           184\n",
      "Discomfort     103\n",
      "Severe Pain    216\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Rotation statistics:\n",
      "Image_Rotation\n",
      "0      284\n",
      "90      61\n",
      "180     89\n",
      "270     69\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Fallback usage:\n",
      "  - Fallback used: 234 images (46.5%)\n",
      "  - Face detected: 269 images (53.5%)\n"
     ]
    }
   ],
   "source": [
    "# CONFIGURATION\n",
    "DATASET_PATH = \"../data/raw/img/Pain Level/\"  # <--- UPDATE THIS PATH\n",
    "DEBUG = True  # Set to False to hide per-image logs\n",
    "\n",
    "data = []\n",
    "stats = {\n",
    "    \"total_files\": 0,\n",
    "    \"images_loaded\": 0,\n",
    "    \"faces_detected\": 0,\n",
    "    \"fallback_crops\": 0,\n",
    "    \"faces_extracted\": 0,\n",
    "    \"errors\": 0\n",
    "}\n",
    "\n",
    "print(\"Starting processing... this may take a few minutes.\")\n",
    "print(f\"Debug mode: {DEBUG}\")\n",
    "print()\n",
    "\n",
    "# Loop through all folders in your directory\n",
    "for folder_name in sorted(os.listdir(DATASET_PATH)):\n",
    "    folder_full_path = os.path.join(DATASET_PATH, folder_name)\n",
    "    \n",
    "    if not os.path.isdir(folder_full_path):\n",
    "        continue\n",
    "\n",
    "    # --- BINNING STRATEGY (Simplified Labels) ---\n",
    "    try:\n",
    "        pain_level = float(folder_name)\n",
    "        if pain_level <= 2.0:\n",
    "            label = 0  # \"Calm\"\n",
    "            label_str = \"Calm\"\n",
    "        elif pain_level <= 4.5:\n",
    "            label = 1  # \"Discomfort\"\n",
    "            label_str = \"Discomfort\"\n",
    "        else:\n",
    "            label = 2  # \"Severe Pain\"\n",
    "            label_str = \"Severe Pain\"\n",
    "    except ValueError:\n",
    "        continue # Skip folders that aren't numbers\n",
    "\n",
    "    img_files = [f for f in os.listdir(folder_full_path)\n",
    "                 if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp', '.tiff'))]\n",
    "    \n",
    "    print(f\"Processing Folder: {folder_name} ({label_str}) - {len(img_files)} images\")\n",
    "    \n",
    "    folder_extracted = 0\n",
    "    folder_fallback = 0\n",
    "    \n",
    "    for img_file in img_files:\n",
    "        img_path = os.path.join(folder_full_path, img_file)\n",
    "        stats[\"total_files\"] += 1\n",
    "        \n",
    "        # Load image\n",
    "        image = cv2.imread(img_path)\n",
    "        if image is None:\n",
    "            stats[\"errors\"] += 1\n",
    "            if DEBUG:\n",
    "                print(f\"  ERROR: Could not load {img_file}\")\n",
    "            continue\n",
    "        \n",
    "        stats[\"images_loaded\"] += 1\n",
    "        \n",
    "        # Extract features using our function\n",
    "        features = extract_face_features(image, img_path)\n",
    "        \n",
    "        if features:\n",
    "            stats[\"faces_extracted\"] += 1\n",
    "            folder_extracted += 1\n",
    "            \n",
    "            # Track fallback usage\n",
    "            if features.get(\"Fallback_Used\", False):\n",
    "                stats[\"fallback_crops\"] += 1\n",
    "                folder_fallback += 1\n",
    "            else:\n",
    "                stats[\"faces_detected\"] += 1\n",
    "            \n",
    "            features[\"Label\"] = label\n",
    "            features[\"Label_String\"] = label_str\n",
    "            features[\"Filename\"] = img_file\n",
    "            features[\"Pain_Level\"] = pain_level\n",
    "            data.append(features)\n",
    "        elif DEBUG and stats[\"total_files\"] % 50 == 0:\n",
    "            print(f\"  No face detected in {img_file}\")\n",
    "    \n",
    "    if folder_extracted > 0:\n",
    "        print(f\"  ‚úì Extracted: {folder_extracted}/{len(img_files)} images\")\n",
    "        if folder_fallback > 0:\n",
    "            print(f\"    - {folder_fallback} used fallback center crop\")\n",
    "    else:\n",
    "        print(f\"  ‚ö† WARNING: No faces extracted from this folder!\")\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Save to CSV\n",
    "output_path = \"../data/processed/processed_pain_img_biomarkers.csv\"\n",
    "os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "df.to_csv(output_path, index=False)\n",
    "\n",
    "# Print summary\n",
    "print()\n",
    "print(\"=\" * 70)\n",
    "print(\"PROCESSING COMPLETE\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Total files scanned:         {stats['total_files']}\")\n",
    "print(f\"Images successfully loaded:  {stats['images_loaded']}\")\n",
    "print(f\"Faces detected:              {stats['faces_detected']}\")\n",
    "print(f\"Fallback crops (no face):    {stats['fallback_crops']}\")\n",
    "print(f\"Total extracted:             {stats['faces_extracted']}\")\n",
    "print(f\"Load errors:                 {stats['errors']}\")\n",
    "print(f\"Success rate:                {100*stats['faces_extracted']/max(1, stats['images_loaded']):.1f}%\")\n",
    "print()\n",
    "print(f\"‚úì Processed {len(df)} images ‚Üí Saved to: {output_path}\")\n",
    "print()\n",
    "print(\"Data shape:\", df.shape)\n",
    "print(\"\\nClasses distribution:\")\n",
    "print(df['Label_String'].value_counts().sort_index())\n",
    "print(\"\\nRotation statistics:\")\n",
    "print(df['Image_Rotation'].value_counts().sort_index())\n",
    "print(\"\\nFallback usage:\")\n",
    "fallback_count = df['Fallback_Used'].sum()\n",
    "print(f\"  - Fallback used: {fallback_count} images ({100*fallback_count/len(df):.1f}%)\")\n",
    "print(f\"  - Face detected: {len(df)-fallback_count} images ({100*(len(df)-fallback_count)/len(df):.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dac78c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DATASET STRUCTURE ANALYSIS\n",
      "============================================================\n",
      "\n",
      "üìÅ Folder: 0 (Pain Level: 0.0)\n",
      "   Total image files: 135\n",
      "   Sample files: ['baby11_baseline1_level-0_class-0_jpeg_jpg.rf.008b92d12c49c01ac790dd1636503286.jpg', 'baby11_baseline3_level-0_class-0_jpeg_jpg.rf.4dcf8e98bda99ba787282bb424c6ea2b.jpg', 'baby11_post-pain2_level-0_class-0_jpeg_jpg.rf.2d768a91171199df387ce5840af73985.jpg']\n",
      "   ‚úì Faces detected in: 0/5 checked\n",
      "   ‚úó No faces in: 5/5 checked\n",
      "\n",
      "üìÅ Folder: 0.5 (Pain Level: 0.5)\n",
      "   Total image files: 3\n",
      "   Sample files: ['baby32_post-pain1_level-0-5_class-1_jpeg_jpg.rf.e8e69ea6fcf9c02e686d41e47619db99.jpg', 'baby36_post-pain1_level-0-5_class-1_jpeg_jpg.rf.391ee7a72194cb0b82e318368c8abdef.jpg', 'baby50_post-pain1_level-0-5_class-1_jpeg_jpg.rf.a1c11b12168308577651a5a47811bbf4.jpg']\n",
      "   ‚úì Faces detected in: 0/3 checked\n",
      "   ‚úó No faces in: 3/3 checked\n",
      "\n",
      "üìÅ Folder: 1 (Pain Level: 1.0)\n",
      "   Total image files: 6\n",
      "   Sample files: ['baby15_during-pain11_level-1_class-1_jpeg_jpg.rf.148e95f4aaf917384454194516e02118.jpg', 'baby27_post-pain1_level-1_class-1_jpeg_jpg.rf.40c315e11f866317ab388dd1e3fe16f4.jpg', 'baby37_during-pain10_level-1_class-1_jpeg_jpg.rf.bc2286dd79861085262a63cd7f271548.jpg']\n",
      "   ‚úì Faces detected in: 0/5 checked\n",
      "   ‚úó No faces in: 5/5 checked\n",
      "\n",
      "üìÅ Folder: 0.5 (Pain Level: 0.5)\n",
      "   Total image files: 3\n",
      "   Sample files: ['baby32_post-pain1_level-0-5_class-1_jpeg_jpg.rf.e8e69ea6fcf9c02e686d41e47619db99.jpg', 'baby36_post-pain1_level-0-5_class-1_jpeg_jpg.rf.391ee7a72194cb0b82e318368c8abdef.jpg', 'baby50_post-pain1_level-0-5_class-1_jpeg_jpg.rf.a1c11b12168308577651a5a47811bbf4.jpg']\n",
      "   ‚úì Faces detected in: 0/3 checked\n",
      "   ‚úó No faces in: 3/3 checked\n",
      "\n",
      "üìÅ Folder: 1 (Pain Level: 1.0)\n",
      "   Total image files: 6\n",
      "   Sample files: ['baby15_during-pain11_level-1_class-1_jpeg_jpg.rf.148e95f4aaf917384454194516e02118.jpg', 'baby27_post-pain1_level-1_class-1_jpeg_jpg.rf.40c315e11f866317ab388dd1e3fe16f4.jpg', 'baby37_during-pain10_level-1_class-1_jpeg_jpg.rf.bc2286dd79861085262a63cd7f271548.jpg']\n",
      "   ‚úì Faces detected in: 2/5 checked\n",
      "   ‚úó No faces in: 3/5 checked\n",
      "\n",
      "üìÅ Folder: 1.5 (Pain Level: 1.5)\n",
      "   Total image files: 21\n",
      "   Sample files: ['baby12_during-pain9_level-1-5_class-1_jpeg_jpg.rf.f41bea1bcd7ff3a1d6eae0beb78f36aa.jpg', 'baby16_post-pain2_level-1-5_class-1_jpeg_jpg.rf.8d8bf25e617e4ba8a488cfe50561a227.jpg', 'baby21_post-pain1-level-1-5_class-1_jpeg_jpg.rf.7707fbfef95c57e7c75e5494e002fc0f.jpg']\n",
      "   ‚úì Faces detected in: 2/5 checked\n",
      "   ‚úó No faces in: 3/5 checked\n",
      "\n",
      "üìÅ Folder: 1.5 (Pain Level: 1.5)\n",
      "   Total image files: 21\n",
      "   Sample files: ['baby12_during-pain9_level-1-5_class-1_jpeg_jpg.rf.f41bea1bcd7ff3a1d6eae0beb78f36aa.jpg', 'baby16_post-pain2_level-1-5_class-1_jpeg_jpg.rf.8d8bf25e617e4ba8a488cfe50561a227.jpg', 'baby21_post-pain1-level-1-5_class-1_jpeg_jpg.rf.7707fbfef95c57e7c75e5494e002fc0f.jpg']\n",
      "   ‚úì Faces detected in: 0/5 checked\n",
      "   ‚úó No faces in: 5/5 checked\n",
      "\n",
      "üìÅ Folder: 2 (Pain Level: 2.0)\n",
      "   Total image files: 19\n",
      "   Sample files: ['baby15_during-pain1_level-2_class-1_jpeg_jpg.rf.89d9c9203d5c9174a5a89b2a9620ba51.jpg', 'baby15_post-pain1_level-2_class-1_jpeg_jpg.rf.204b1010aefe8629e05c5c3899c6e239.jpg', 'baby26_during-pain7_level-2_class-1_jpeg_jpg.rf.8361bcdad60d3d862af845769bc9f948.jpg']\n",
      "   ‚úì Faces detected in: 0/5 checked\n",
      "   ‚úó No faces in: 5/5 checked\n",
      "\n",
      "üìÅ Folder: 2 (Pain Level: 2.0)\n",
      "   Total image files: 19\n",
      "   Sample files: ['baby15_during-pain1_level-2_class-1_jpeg_jpg.rf.89d9c9203d5c9174a5a89b2a9620ba51.jpg', 'baby15_post-pain1_level-2_class-1_jpeg_jpg.rf.204b1010aefe8629e05c5c3899c6e239.jpg', 'baby26_during-pain7_level-2_class-1_jpeg_jpg.rf.8361bcdad60d3d862af845769bc9f948.jpg']\n",
      "   ‚úì Faces detected in: 0/5 checked\n",
      "   ‚úó No faces in: 5/5 checked\n",
      "\n",
      "üìÅ Folder: 2.5 (Pain Level: 2.5)\n",
      "   Total image files: 8\n",
      "   Sample files: ['baby14_post-pain1_level-2-5_class-1_jpeg_jpg.rf.0453524f5829752020f0da984af290fb.jpg', 'baby3_during-pain6_level-2-5_class-1_jpg.rf.d58dba906a44190b15df48d3c18daa1d.jpg', 'baby41_during-pain18_level-2-5_class-1_jpeg_jpg.rf.1c12c9177e7b48f6114581b3a82dcdca.jpg']\n",
      "   ‚úì Faces detected in: 0/5 checked\n",
      "   ‚úó No faces in: 5/5 checked\n",
      "\n",
      "üìÅ Folder: 2.5 (Pain Level: 2.5)\n",
      "   Total image files: 8\n",
      "   Sample files: ['baby14_post-pain1_level-2-5_class-1_jpeg_jpg.rf.0453524f5829752020f0da984af290fb.jpg', 'baby3_during-pain6_level-2-5_class-1_jpg.rf.d58dba906a44190b15df48d3c18daa1d.jpg', 'baby41_during-pain18_level-2-5_class-1_jpeg_jpg.rf.1c12c9177e7b48f6114581b3a82dcdca.jpg']\n",
      "   ‚úì Faces detected in: 1/5 checked\n",
      "   ‚úó No faces in: 4/5 checked\n",
      "\n",
      "üìÅ Folder: 3 (Pain Level: 3.0)\n",
      "   Total image files: 37\n",
      "   Sample files: ['baby12_during-pain3_level-7_class-3_jpeg_jpg.rf.54f36a803073f94aecde8510df1af4e1.jpg', 'baby14_during-pain1_level-3_class-1_jpeg_jpg.rf.09e03101bbd9243ec5e6179256a4c9a2.jpg', 'baby15_during-pain2_level-3_class-1_jpeg_jpg.rf.d1924aa423de627f6acb4798909949b6.jpg']\n",
      "   ‚úì Faces detected in: 1/5 checked\n",
      "   ‚úó No faces in: 4/5 checked\n",
      "\n",
      "üìÅ Folder: 3 (Pain Level: 3.0)\n",
      "   Total image files: 37\n",
      "   Sample files: ['baby12_during-pain3_level-7_class-3_jpeg_jpg.rf.54f36a803073f94aecde8510df1af4e1.jpg', 'baby14_during-pain1_level-3_class-1_jpeg_jpg.rf.09e03101bbd9243ec5e6179256a4c9a2.jpg', 'baby15_during-pain2_level-3_class-1_jpeg_jpg.rf.d1924aa423de627f6acb4798909949b6.jpg']\n",
      "   ‚úì Faces detected in: 0/5 checked\n",
      "   ‚úó No faces in: 5/5 checked\n",
      "\n",
      "üìÅ Folder: 3.5 (Pain Level: 3.5)\n",
      "   Total image files: 17\n",
      "   Sample files: ['baby18_during-pain1_level-3-5_class-2_jpeg_jpg.rf.8aed99aaf22ac62a5283aa606af865f5.jpg', 'baby21_during-pain6-level-3-5_class-2_jpeg_jpg.rf.41904b191645ea4be800ce28343b4a45.jpg', 'baby31_during-pain10_level-3-5_class-2_jpeg_jpg.rf.7b00cc51c0c8766a56de8a773b701b79.jpg']\n",
      "   ‚úì Faces detected in: 0/5 checked\n",
      "   ‚úó No faces in: 5/5 checked\n",
      "\n",
      "üìÅ Folder: 3.5 (Pain Level: 3.5)\n",
      "   Total image files: 17\n",
      "   Sample files: ['baby18_during-pain1_level-3-5_class-2_jpeg_jpg.rf.8aed99aaf22ac62a5283aa606af865f5.jpg', 'baby21_during-pain6-level-3-5_class-2_jpeg_jpg.rf.41904b191645ea4be800ce28343b4a45.jpg', 'baby31_during-pain10_level-3-5_class-2_jpeg_jpg.rf.7b00cc51c0c8766a56de8a773b701b79.jpg']\n",
      "   ‚úì Faces detected in: 1/5 checked\n",
      "   ‚úó No faces in: 4/5 checked\n",
      "\n",
      "üìÅ Folder: 4 (Pain Level: 4.0)\n",
      "   Total image files: 33\n",
      "   Sample files: ['baby18_during-pain7_level-4_class-2_jpeg_jpg.rf.662aa961bdef22b36e0a1331d799e7dd.jpg', 'baby21_during-pain1-level-4_class-2_jpeg_jpg.rf.835badc3c6dc96be4d89e76a4e2078f1.jpg', 'baby23_during-pain7_level-4_class-2_jpeg_jpg.rf.0a0833d7402ebeb6c3ba0b1f87c54fd9.jpg']\n",
      "   ‚úì Faces detected in: 1/5 checked\n",
      "   ‚úó No faces in: 4/5 checked\n",
      "\n",
      "üìÅ Folder: 4 (Pain Level: 4.0)\n",
      "   Total image files: 33\n",
      "   Sample files: ['baby18_during-pain7_level-4_class-2_jpeg_jpg.rf.662aa961bdef22b36e0a1331d799e7dd.jpg', 'baby21_during-pain1-level-4_class-2_jpeg_jpg.rf.835badc3c6dc96be4d89e76a4e2078f1.jpg', 'baby23_during-pain7_level-4_class-2_jpeg_jpg.rf.0a0833d7402ebeb6c3ba0b1f87c54fd9.jpg']\n",
      "   ‚úì Faces detected in: 1/5 checked\n",
      "   ‚úó No faces in: 4/5 checked\n",
      "\n",
      "üìÅ Folder: 4.5 (Pain Level: 4.5)\n",
      "   Total image files: 8\n",
      "   Sample files: ['baby14_during-pain10_level-4-5_class-2_jpeg_jpg.rf.322748c1e4e047ca9350f5032f408337.jpg', 'baby14_during-pain2_level-4-5_class-2_jpeg_jpg.rf.8058f8db9c9f20cddcac31cf6a39caff.jpg', 'baby16_during-pain7_level-4-5_class-2_jpeg_jpg.rf.bf0a4becd88285b20633682cc10c1313.jpg']\n",
      "   ‚úì Faces detected in: 1/5 checked\n",
      "   ‚úó No faces in: 4/5 checked\n",
      "\n",
      "üìÅ Folder: 4.5 (Pain Level: 4.5)\n",
      "   Total image files: 8\n",
      "   Sample files: ['baby14_during-pain10_level-4-5_class-2_jpeg_jpg.rf.322748c1e4e047ca9350f5032f408337.jpg', 'baby14_during-pain2_level-4-5_class-2_jpeg_jpg.rf.8058f8db9c9f20cddcac31cf6a39caff.jpg', 'baby16_during-pain7_level-4-5_class-2_jpeg_jpg.rf.bf0a4becd88285b20633682cc10c1313.jpg']\n",
      "   ‚úì Faces detected in: 0/5 checked\n",
      "   ‚úó No faces in: 5/5 checked\n",
      "\n",
      "üìÅ Folder: 5 (Pain Level: 5.0)\n",
      "   Total image files: 46\n",
      "   Sample files: ['baby14_during-pain3_level-5_class-2_jpeg_jpg.rf.a443f82205e80040901449d699926c3c.jpg', 'baby15_during-pain9_level-5_class-2_jpeg_jpg.rf.71198bf23adf79d1e1b34aa5ff3ad525.jpg', 'baby21_during-pain5-level-5_class-2_jpeg_jpg.rf.1ca1ebaabd0d6a59fe8f4d458eb0c3ea.jpg']\n",
      "   ‚úì Faces detected in: 0/5 checked\n",
      "   ‚úó No faces in: 5/5 checked\n",
      "\n",
      "üìÅ Folder: 5 (Pain Level: 5.0)\n",
      "   Total image files: 46\n",
      "   Sample files: ['baby14_during-pain3_level-5_class-2_jpeg_jpg.rf.a443f82205e80040901449d699926c3c.jpg', 'baby15_during-pain9_level-5_class-2_jpeg_jpg.rf.71198bf23adf79d1e1b34aa5ff3ad525.jpg', 'baby21_during-pain5-level-5_class-2_jpeg_jpg.rf.1ca1ebaabd0d6a59fe8f4d458eb0c3ea.jpg']\n",
      "   ‚úì Faces detected in: 0/5 checked\n",
      "   ‚úó No faces in: 5/5 checked\n",
      "\n",
      "üìÅ Folder: 5.5 (Pain Level: 5.5)\n",
      "   Total image files: 7\n",
      "   Sample files: ['baby14_during-pain9_level-5-5-_class-2_jpeg_jpg.rf.62cfc15703d6c9c50c2486c3358b037a.jpg', 'baby17_during-pain2_level-5-5_class-2_jpeg_jpg.rf.0e4b6cb4509a7252ca37eb4d5a87ef46.jpg', 'baby17_during-pain6_level-5-5_class-2_jpeg_jpg.rf.90d55ef99e081235fd38135b26ff31df.jpg']\n",
      "   ‚úì Faces detected in: 0/5 checked\n",
      "   ‚úó No faces in: 5/5 checked\n",
      "\n",
      "üìÅ Folder: 5.5 (Pain Level: 5.5)\n",
      "   Total image files: 7\n",
      "   Sample files: ['baby14_during-pain9_level-5-5-_class-2_jpeg_jpg.rf.62cfc15703d6c9c50c2486c3358b037a.jpg', 'baby17_during-pain2_level-5-5_class-2_jpeg_jpg.rf.0e4b6cb4509a7252ca37eb4d5a87ef46.jpg', 'baby17_during-pain6_level-5-5_class-2_jpeg_jpg.rf.90d55ef99e081235fd38135b26ff31df.jpg']\n",
      "   ‚úì Faces detected in: 0/5 checked\n",
      "   ‚úó No faces in: 5/5 checked\n",
      "\n",
      "üìÅ Folder: 6 (Pain Level: 6.0)\n",
      "   Total image files: 24\n",
      "   Sample files: ['baby12_during-pain1_level-6_class-2_jpeg_jpg.rf.c513eab47ed8ec3466bcbb1ee06f572c.jpg', 'baby12_during-pain7_level-6_class-2_jpeg_jpg.rf.5545cc7a21906af142ef9dd8bdce0571.jpg', 'baby14_during-pain8_level-6-_class-2_jpeg_jpg.rf.85566b8744bd7e5e3ef527de5e073e34.jpg']\n",
      "   ‚úì Faces detected in: 0/5 checked\n",
      "   ‚úó No faces in: 5/5 checked\n",
      "\n",
      "üìÅ Folder: 6 (Pain Level: 6.0)\n",
      "   Total image files: 24\n",
      "   Sample files: ['baby12_during-pain1_level-6_class-2_jpeg_jpg.rf.c513eab47ed8ec3466bcbb1ee06f572c.jpg', 'baby12_during-pain7_level-6_class-2_jpeg_jpg.rf.5545cc7a21906af142ef9dd8bdce0571.jpg', 'baby14_during-pain8_level-6-_class-2_jpeg_jpg.rf.85566b8744bd7e5e3ef527de5e073e34.jpg']\n",
      "   ‚úì Faces detected in: 0/5 checked\n",
      "   ‚úó No faces in: 5/5 checked\n",
      "\n",
      "üìÅ Folder: 6.5 (Pain Level: 6.5)\n",
      "   Total image files: 15\n",
      "   Sample files: ['baby12_during-pain6_level-6-5_class-3_jpeg_jpg.rf.840432407e3b4c3042edda3232dee5d5.jpg', 'baby21_during-pain4-level-6-5_class-3_jpeg_jpg.rf.e7c4f0fc334ea85dd2f07de19ce3ea45.jpg', 'baby23_during-pain5_level-6-5_class-3_jpeg_jpg.rf.8657bd36f5a0fe491c7411e644fc5b84.jpg']\n",
      "   ‚úì Faces detected in: 0/5 checked\n",
      "   ‚úó No faces in: 5/5 checked\n",
      "\n",
      "üìÅ Folder: 6.5 (Pain Level: 6.5)\n",
      "   Total image files: 15\n",
      "   Sample files: ['baby12_during-pain6_level-6-5_class-3_jpeg_jpg.rf.840432407e3b4c3042edda3232dee5d5.jpg', 'baby21_during-pain4-level-6-5_class-3_jpeg_jpg.rf.e7c4f0fc334ea85dd2f07de19ce3ea45.jpg', 'baby23_during-pain5_level-6-5_class-3_jpeg_jpg.rf.8657bd36f5a0fe491c7411e644fc5b84.jpg']\n",
      "   ‚úì Faces detected in: 1/5 checked\n",
      "   ‚úó No faces in: 4/5 checked\n",
      "\n",
      "üìÅ Folder: 7 (Pain Level: 7.0)\n",
      "   Total image files: 123\n",
      "   Sample files: ['baby11_during-pain4_level-7_class-3_jpeg_jpg.rf.1537534ec674d2783fc84d761fdf776c.jpg', 'baby12_during-pain5_level-7_class-3_jpeg_jpg.rf.5e813e27594e131cfa039aafe8753869.jpg', 'baby14_during-pain4_level-7_class-3_jpeg_jpg.rf.5f007e15f46480d3403b796def80c4cb.jpg']\n",
      "   ‚úì Faces detected in: 1/5 checked\n",
      "   ‚úó No faces in: 4/5 checked\n",
      "\n",
      "üìÅ Folder: 7 (Pain Level: 7.0)\n",
      "   Total image files: 123\n",
      "   Sample files: ['baby11_during-pain4_level-7_class-3_jpeg_jpg.rf.1537534ec674d2783fc84d761fdf776c.jpg', 'baby12_during-pain5_level-7_class-3_jpeg_jpg.rf.5e813e27594e131cfa039aafe8753869.jpg', 'baby14_during-pain4_level-7_class-3_jpeg_jpg.rf.5f007e15f46480d3403b796def80c4cb.jpg']\n",
      "   ‚úì Faces detected in: 0/5 checked\n",
      "   ‚úó No faces in: 5/5 checked\n",
      "\n",
      "üìÅ Folder: 8 (Pain Level: 8.0)\n",
      "   Total image files: 1\n",
      "   Sample files: ['baby42_during-pain8_level-6_class-2_jpeg_jpg.rf.434d26d6bcb9f42609c64f7172e4a839.jpg']\n",
      "   ‚úì Faces detected in: 0/1 checked\n",
      "   ‚úó No faces in: 1/1 checked\n",
      "\n",
      "============================================================\n",
      "SUMMARY\n",
      "============================================================\n",
      "Total images checked: 74\n",
      "Images with faces: 6\n",
      "Images without faces: 68\n",
      "Face detection rate: 8.1%\n",
      "\n",
      "üí° POSSIBLE REASONS for low processing:\n",
      "   1. Image format not recognized (check file extensions)\n",
      "   2. Face detector not finding faces (try lowering confidence threshold)\n",
      "   3. Images too small or unclear faces\n",
      "   4. Dataset path incorrect or folder structure different\n",
      "============================================================\n",
      "   ‚úì Faces detected in: 0/5 checked\n",
      "   ‚úó No faces in: 5/5 checked\n",
      "\n",
      "üìÅ Folder: 8 (Pain Level: 8.0)\n",
      "   Total image files: 1\n",
      "   Sample files: ['baby42_during-pain8_level-6_class-2_jpeg_jpg.rf.434d26d6bcb9f42609c64f7172e4a839.jpg']\n",
      "   ‚úì Faces detected in: 0/1 checked\n",
      "   ‚úó No faces in: 1/1 checked\n",
      "\n",
      "============================================================\n",
      "SUMMARY\n",
      "============================================================\n",
      "Total images checked: 74\n",
      "Images with faces: 6\n",
      "Images without faces: 68\n",
      "Face detection rate: 8.1%\n",
      "\n",
      "üí° POSSIBLE REASONS for low processing:\n",
      "   1. Image format not recognized (check file extensions)\n",
      "   2. Face detector not finding faces (try lowering confidence threshold)\n",
      "   3. Images too small or unclear faces\n",
      "   4. Dataset path incorrect or folder structure different\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# DIAGNOSTIC: Check dataset structure and face detection issues\n",
    "import os\n",
    "\n",
    "DATASET_PATH = \"../data/raw/img/Pain Level/\"\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"DATASET STRUCTURE ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "total_images = 0\n",
    "processed_images = 0\n",
    "no_face_detected = 0\n",
    "invalid_files = 0\n",
    "\n",
    "for folder_name in os.listdir(DATASET_PATH):\n",
    "    folder_full_path = os.path.join(DATASET_PATH, folder_name)\n",
    "    \n",
    "    if not os.path.isdir(folder_full_path):\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        pain_level = float(folder_name)\n",
    "        print(f\"\\nüìÅ Folder: {folder_name} (Pain Level: {pain_level})\")\n",
    "    except ValueError:\n",
    "        print(f\"\\n‚ö†Ô∏è  Skipping folder (not a number): {folder_name}\")\n",
    "        continue\n",
    "    \n",
    "    image_files = [f for f in os.listdir(folder_full_path) \n",
    "                   if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp', '.tiff'))]\n",
    "    \n",
    "    print(f\"   Total image files: {len(image_files)}\")\n",
    "    \n",
    "    if len(image_files) > 0:\n",
    "        print(f\"   Sample files: {image_files[:3]}\")\n",
    "    \n",
    "    # Try to load and detect faces in first few images\n",
    "    faces_found = 0\n",
    "    no_faces = 0\n",
    "    for img_file in image_files[:5]:  # Check first 5 images\n",
    "        img_path = os.path.join(folder_full_path, img_file)\n",
    "        image = cv2.imread(img_path)\n",
    "        \n",
    "        if image is None:\n",
    "            print(f\"      ‚úó {img_file} - failed to load\")\n",
    "            continue\n",
    "        \n",
    "        total_images += 1\n",
    "        \n",
    "        # Try to detect face\n",
    "        if use_dnn:\n",
    "            faces = detect_faces_dnn(image)\n",
    "        else:\n",
    "            faces = detect_faces_haar(image)\n",
    "        \n",
    "        if len(faces) > 0:\n",
    "            faces_found += 1\n",
    "            processed_images += 1\n",
    "        else:\n",
    "            no_faces += 1\n",
    "            no_face_detected += 1\n",
    "    \n",
    "    if len(image_files) > 0:\n",
    "        print(f\"   ‚úì Faces detected in: {faces_found}/{min(5, len(image_files))} checked\")\n",
    "        print(f\"   ‚úó No faces in: {no_faces}/{min(5, len(image_files))} checked\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Total images checked: {total_images}\")\n",
    "print(f\"Images with faces: {processed_images}\")\n",
    "print(f\"Images without faces: {no_face_detected}\")\n",
    "print(f\"Face detection rate: {100*processed_images/total_images if total_images > 0 else 0:.1f}%\")\n",
    "print(\"\\nüí° POSSIBLE REASONS for low processing:\")\n",
    "print(\"   1. Image format not recognized (check file extensions)\")\n",
    "print(\"   2. Face detector not finding faces (try lowering confidence threshold)\")\n",
    "print(\"   3. Images too small or unclear faces\")\n",
    "print(\"   4. Dataset path incorrect or folder structure different\")\n",
    "print(\"=\" * 60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4420d56",
   "metadata": {},
   "source": [
    "# ‚úÖ Processing Summary & Improvements\n",
    "\n",
    "## What's New:\n",
    "\n",
    "### 1. **MediaPipe Face Detection** üéØ\n",
    "- More robust than Haar Cascade and DNN\n",
    "- Better at detecting faces in different angles/expressions\n",
    "- Handles crying and side-profile expressions\n",
    "- Confidence threshold: 0.3 (catches more difficult cases)\n",
    "\n",
    "### 2. **Smart Detection Hierarchy** üîÄ\n",
    "When processing each image:\n",
    "1. **MediaPipe** ‚Üí Most robust (catches expressions, angles)\n",
    "2. **OpenCV DNN** ‚Üí Accurate fallback\n",
    "3. **Haar Cascade** ‚Üí Fast fallback\n",
    "4. **Center Crop** ‚Üí Last resort (60% center crop if no face detected)\n",
    "\n",
    "### 3. **Auto-Rotation** üîÑ\n",
    "- Tests 4 rotations: 0¬∞, 90¬∞, 180¬∞, 270¬∞\n",
    "- Selects rotation with best face detection\n",
    "- Handles horizontal/landscape images automatically\n",
    "- Tracks which rotation was used\n",
    "\n",
    "### 4. **Fallback Mechanism** üìã\n",
    "- If no face detected: uses 60% center crop of image\n",
    "- Prevents loss of ~90% of images without detected faces\n",
    "- Marked in CSV with `Fallback_Used` flag\n",
    "- Statistics show fallback usage rate\n",
    "\n",
    "### 5. **Enhanced CSV Output** üìä\n",
    "New columns:\n",
    "- `Image_Rotation`: Which rotation was optimal (0, 90, 180, 270)\n",
    "- `Fallback_Used`: True if center crop was used instead of face\n",
    "- `Faces_Size`: Actual face region area\n",
    "\n",
    "## Usage:\n",
    "\n",
    "```python\n",
    "# Check fallback usage\n",
    "print(f\"Fallback rate: {(df['Fallback_Used'].sum() / len(df) * 100):.1f}%\")\n",
    "\n",
    "# Filter to only detected faces\n",
    "df_detected = df[df['Fallback_Used'] == False]\n",
    "\n",
    "# Filter to fallback crops\n",
    "df_fallback = df[df['Fallback_Used'] == True]\n",
    "```\n",
    "\n",
    "## Expected Improvements:\n",
    "‚úÖ Better detection of crying/expressive faces\n",
    "‚úÖ Handles horizontal images correctly\n",
    "‚úÖ Less data loss (fallback prevents ~90% waste)\n",
    "‚úÖ More consistent features across dataset\n",
    "‚úÖ Ready for model training!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
